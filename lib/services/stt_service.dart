import 'dart:io';
import 'dart:convert';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter/foundation.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:http/http.dart' as http;

/// Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Speech-to-Text ‡πÉ‡∏ä‡πâ OpenAI Whisper API
/// ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å platform: iOS/Android (Simulator + ‡∏à‡∏£‡∏¥‡∏á), macOS
class STTService {
  static final STTService _instance = STTService._internal();
  factory STTService() => _instance;
  STTService._internal();

  final AudioRecorder _recorder = AudioRecorder();
  bool _isInitialized = false;
  bool _isListening = false;
  String _lastRecognizedText = '';

  // OpenAI API Key (‡πÉ‡∏ä‡πâ key ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ChatGPT service)
  static String get _apiKey => dotenv.env['OPENAI_API_KEY'] ?? '';
  static const String _whisperUrl =
      'https://api.openai.com/v1/audio/transcriptions';

  String? _currentRecordingPath;

  // Callbacks
  Function(String)? onResult;
  Function(String)? onPartialResult;
  Function()? onListeningStarted;
  Function()? onListeningStopped;
  Function(String)? onError;

  /// ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
  bool get isListening => _isListening;

  /// ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ STT ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
  bool get isAvailable => _isInitialized;

  /// ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
  String get lastRecognizedText => _lastRecognizedText;

  /// Initialize STT ‚Äî ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏°‡∏Ñ‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
  Future<bool> init() async {
    if (_isInitialized) return true;

    try {
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ microphone permission ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
      final hasPermission = await _recorder.hasPermission();
      debugPrint('üé§ Whisper STT: hasPermission = $hasPermission');

      if (!hasPermission) {
        debugPrint('üé§ Whisper STT: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô');
        onError?.call('‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô');
        return false;
      }

      _isInitialized = true;
      debugPrint('üé§ Whisper STT: Initialized ‚úÖ');
      return true;
    } catch (e) {
      debugPrint('üé§ Whisper STT Init Error: $e');
      onError?.call('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô‡πÑ‡∏î‡πâ: $e');
      return false;
    }
  }

  /// ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á)
  Future<void> startListening() async {
    if (!_isInitialized) {
      final success = await init();
      if (!success) {
        onError?.call('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô‡πÑ‡∏î‡πâ');
        return;
      }
    }

    if (_isListening) {
      // ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
      await stopListening();
      return;
    }

    try {
      // Set listening state BEFORE async start ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô race condition
      _isListening = true;
      _lastRecognizedText = '';
      onListeningStarted?.call();
      onPartialResult?.call('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á... ‡∏û‡∏π‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î‡πÑ‡∏°‡∏Ñ‡πå‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î üé§');

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á file path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
      final dir = await getTemporaryDirectory();
      _currentRecordingPath =
          '${dir.path}/stt_recording_${DateTime.now().millisecondsSinceEpoch}.m4a';

      // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
      await _recorder.start(
        const RecordConfig(
          encoder: AudioEncoder.aacLc,
          sampleRate: 16000,
          numChannels: 1,
          bitRate: 64000,
        ),
        path: _currentRecordingPath!,
      );

      debugPrint('üé§ Whisper STT: Start recording ‚Üí $_currentRecordingPath');
    } catch (e) {
      debugPrint('üé§ Whisper STT: Start error: $e');
      _isListening = false;
      onListeningStopped?.call();
      onError?.call('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ: $e');
    }
  }

  /// ‡∏´‡∏¢‡∏∏‡∏î‡∏ü‡∏±‡∏á (‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á Whisper API)
  Future<void> stopListening() async {
    if (!_isListening) return;

    try {
      final path = await _recorder.stop();
      _isListening = false;
      debugPrint('üé§ Whisper STT: Stopped recording ‚Üí $path');

      if (path != null && path.isNotEmpty) {
        // ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á
        onPartialResult?.call('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...');

        // ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ Whisper API
        final text = await _transcribeWithWhisper(path);

        if (text != null && text.isNotEmpty) {
          _lastRecognizedText = text;
          debugPrint('üé§ Whisper STT: Result ‚Üí $text');
          onResult?.call(text);
        } else {
          debugPrint('üé§ Whisper STT: No text recognized');
          onPartialResult?.call('');
        }

        // ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        try {
          final file = File(path);
          if (await file.exists()) await file.delete();
        } catch (_) {}
      }
    } catch (e) {
      debugPrint('üé§ Whisper STT: Stop error: $e');
      _isListening = false;
      onError?.call('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á');
    } finally {
      onListeningStopped?.call();
    }
  }

  /// ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ü‡∏±‡∏á
  Future<void> cancelListening() async {
    if (!_isListening) return;

    try {
      await _recorder.stop();
    } catch (_) {}

    _isListening = false;
    _lastRecognizedText = '';

    // ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    if (_currentRecordingPath != null) {
      try {
        final file = File(_currentRecordingPath!);
        if (await file.exists()) await file.delete();
      } catch (_) {}
    }

    onListeningStopped?.call();
  }

  /// ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ OpenAI Whisper API
  Future<String?> _transcribeWithWhisper(String filePath) async {
    try {
      final file = File(filePath);
      if (!await file.exists()) {
        debugPrint('üé§ Whisper: File not found: $filePath');
        return null;
      }

      final fileSize = await file.length();
      debugPrint('üé§ Whisper: Sending file ($fileSize bytes)');

      // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (< 1KB) ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á
      if (fileSize < 1000) {
        debugPrint('üé§ Whisper: File too small, likely no audio');
        return null;
      }

      final request = http.MultipartRequest('POST', Uri.parse(_whisperUrl));
      request.headers['Authorization'] = 'Bearer $_apiKey';
      request.fields['model'] = 'whisper-1';
      request.fields['language'] = 'th'; // ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
      request.fields['response_format'] = 'json';
      request.files.add(await http.MultipartFile.fromPath('file', filePath));

      final response = await request.send();
      final responseBody = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        final json = jsonDecode(responseBody);
        final text = json['text'] as String?;
        debugPrint('üé§ Whisper: Success ‚Üí "$text"');
        return text?.trim();
      } else {
        debugPrint('üé§ Whisper: Error ${response.statusCode}: $responseBody');
        onError?.call('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á');
        return null;
      }
    } catch (e) {
      debugPrint('üé§ Whisper: Exception: $e');
      onError?.call('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠');
      return null;
    }
  }

  /// ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏≤ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compatibility)
  void setLocale(String localeId) {
    // Whisper ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    debugPrint('üé§ Whisper STT: setLocale ‚Üí $localeId (auto-detected)');
  }

  /// ‡∏õ‡∏¥‡∏î STT
  void dispose() {
    cancelListening();
    _recorder.dispose();
    onResult = null;
    onPartialResult = null;
    onListeningStarted = null;
    onListeningStopped = null;
    onError = null;
  }
}
